hypergprior.mod <- bas.lm(Y~.,train, prior = "hyper-g",method = "MCMC",MCMC.iterations = 10000, modelprior = tr.beta.binomial(1,1,N.train-2))
hypergprior.pred <- predict(hypergprior.mod, test[ ,-ncol(test)], se.fit=TRUE)
hypergprior.pred.mat <- post.samples.gprior(2500, hypergprior.mod, hypergprior.pred, test.samp)
hyperg.phat <- sum(hypergprior.mod$postprobs*hypergprior.mod$size)
hypergprior.conf <- confint(hypergprior.pred)
#Non-Local Priors
nlp.pred <- matrix(0,nrow = nrow(test), ncol=3)
nlp.modselect <- quiet(modelSelection(y=Y.samp,x=X.samp, data= train, scale = FALSE,center = FALSE))
nlp.postsamp <- rnlp(msfit=nlp.modselect, niter = 2500,burnin = 1000)
nlp.betasamp <- nlp.postsamp[ , 2:(ncol(nlp.postsamp)-1)]
nlp.phisamp <- nlp.postsamp[ , ncol(nlp.postsamp)]
nlp.pred.mean <- test.samp %*% t(nlp.betasamp)
nlp.pred.mat <- t(apply(nlp.pred.mean, 1, rnorm, n=ncol(nlp.pred.mean), sd=sqrt(nlp.phisamp)))
colnames(nlp.pred) <- c("Predicted", "2.5%", "97.5%")
nlp.pred[, 2:3] <-  t(apply(nlp.pred.mat, 1, quantile, probs=c(0.025,0.975)))
nlp.pred[, 1] <-  rowMeans(nlp.pred.mat)
nlp.phat <- mean(rowSums(nlp.modselect$postSample))
#Horeshoe
HS.pred <- matrix(0,nrow = nrow(test), ncol=3)
HS.mod <- quiet(horseshoe(Y.samp,X.samp,method.tau = "halfCauchy", method.sigma = "Jeffreys",nmc = 2500))
HS.vs <- HS.var.select(HS.mod, Y.samp, method = "intervals")
colnames(HS.pred) <- c("Predicted", "2.5%", "97.5%")
HS.pred.mat.mean <-  test.samp %*% HS.mod$BetaSamples
HS.pred.mat <- t(apply(HS.pred.mat.mean, 1, rnorm, n=ncol(HS.pred.mat.mean), sd=sqrt(HS.mod$Sigma2Samples)))
HS.pred[, 2:3] <-  t(apply(HS.pred.mat, 1, quantile, probs=c(0.025,0.975)))
HS.pred[, 1] <-  test.samp %*% HS.mod$BetaHat
alpha <- 0.5
effsamp <- ncol(HS.mod$BetaSamples)
left.50 <- floor(alpha*effsamp/2)
right.50 <- ceiling((1-alpha/2)*effsamp)
BetaSort <- apply(HS.mod$BetaSamples, 1, sort, decreasing = F)
left.points <- BetaSort[left.50, ]
right.points <- BetaSort[right.50, ]
HS.vs5 <- as.numeric( 1 - ( (left.points <= 0) & (right.points >= 0) ))
#Note sure how to calculate ; currently doing 50% credible intervals
HS.phat <- sum(HS.vs5)
#Spike & slab LASSO
sslasso.mod <- SSLASSO(X.samp[ ,-1], Y.samp, variance = "unknown") # you dont need to give a coefficient column seperately
coef.sslasso <- sslasso.mod$beta[ ,100]
sslasso.pred <- rep(sslasso.mod$intercept[ ,100], nrow(test.samp))+test.samp[ ,-1] %*% coef.sslasso
sslasso.phat <- sum(abs(coef.sslasso)>0)+1 # Include Intercept
#EMVS
p <- ncol(X.samp)-1
epsilon <- 10^{-5}
a.em <- b.em <- 1
beta.init <- rep(1,p)
sigma.init <- 1
v0 <- seq(0.001,15,length.out=1000)
v1 <- 1000
# independent =TRUE, temp=1 and betainit set to default
EMVS.mod <- quiet(EMVS(Y= Y.samp, X = X.samp[ ,-1],v0=v0,v1=v1,
type="betabinomial",
sigma_init = sigma.init ,
epsilon=epsilon,a=a.em,b=b.em))
# EMVS.mod <- quiet(EMVS(Y= Y.samp, X = X.samp[ ,-1],v0=v0,v1=v1,
#                        type="betabinomial",beta_init = beta.init,
#                        sigma_init = sigma.init ,independent = FALSE,
#                        epsilon=epsilon,a=a.em,b=b.em, temperature=0.2))
#EMVS.best <- quiet(EMVSbest(EMVS.mod))
emvs.coef <- EMVS.mod$betas[1, ]
emvs.pred <- test.samp[ ,-1] %*% emvs.coef
EMVS.phat <- length(which(EMVS.mod$prob_inclusion[1,]>=0.5))
#SCAD
scad.mod <-  cv.ncvreg(X.samp[ ,-1], Y.samp, family = "gaussian", penalty = "SCAD")
scad.pred <- predict(scad.mod, test.samp[ ,-1])
scad.phat <- sum(abs(coef(scad.mod))>0)
#MCP
mcp.mod <-  cv.ncvreg(X.samp[ ,-1], Y.samp, family = "gaussian", penalty = "MCP")
mcp.pred <- predict(mcp.mod, test.samp[ ,-1])
mcp.phat <- sum(abs(coef(mcp.mod))>0)
# LASSO lambda min
lasso.mod <- cv.glmnet(X.samp[ ,-1], Y.samp, family = "gaussian")
lasso.pred.min <- predict(lasso.mod, test.samp[ ,-1], s="lambda.min")
lasso.min.phat <- sum(abs(coef(lasso.mod, s="lambda.min"))>0)
# Lasso Lambda 1se
lasso.pred.1se <- predict(lasso.mod, test.samp[ ,-1], s="lambda.1se")
lasso.1se.phat <- sum(abs(coef(lasso.mod, s="lambda.1se"))>0)
# Elastic net
alp <- seq(0.1, 0.95, 0.05)
search <- foreach(i = alp, .combine = rbind, .packages = "glmnet") %dopar% {
cv <- cv.glmnet(X.samp[ , -1], Y.samp, family = "gaussian", nfold = 10, type.measure = "deviance", parallel = TRUE, alpha = i)
data.frame(cvm = cv$cvm[cv$lambda == cv$lambda.min], lambda.min = cv$lambda.min, alpha = i)
}
cv3 <- search[search$cvm == min(search$cvm), ]
elastic.mod <- glmnet(X.samp[ , -1], Y.samp, family = "gaussian", lambda = cv3$lambda.min, alpha = cv3$alpha)
elastic.pred <- predict(elastic.mod, test.samp[ ,-1])
elastic.phat <- sum(abs(coef(elastic.mod))>0)
#JZS
JZS.mod <- bas.lm(Y~., train, prior = "JZS",method = "MCMC",MCMC.iterations = 10000, modelprior = tr.beta.binomial(1,1,N.train-2))
JZS.pred <- predict(JZS.mod, test[ ,-ncol(test)], se.fit=TRUE)
JZS.pred.mat <- post.samples.gprior(2500, JZS.mod,JZS.pred, test.samp)
JZS.phat <- sum(JZS.mod$postprobs*JZS.mod$size)
JZS.conf <- confint(JZS.pred)
#ZS-null
ZSnull.mod <- bas.lm(Y~., train, prior = "ZS-null",method = "MCMC",MCMC.iterations = 10000, modelprior = tr.beta.binomial(1,1,N.train-2))
ZSnull.pred <- predict(ZSnull.mod, test[ ,-ncol(test)], se.fit=TRUE)
ZSnull.pred.mat <- post.samples.gprior(2500, ZSnull.mod,ZSnull.pred, test.samp)
ZSnull.phat <- sum(ZSnull.mod$postprobs*ZSnull.mod$size)
ZSnull.conf <- confint(ZSnull.pred)
full.mod.pred <- matrix(NA, nrow = N.test, ncol = 3)
fullmod.conf <- full.mod.pred[ ,2:3]
full.phat <- NA
# full model
if(p<N.train){
full.mod <- lm(Y~.,data = train)
full.mod.pred <- predict(full.mod, newdata=test[ ,-ncol(test)], interval="prediction")
full.phat <- length(full.mod$coefficients)
fullmod.conf <- full.mod.pred[ ,2:3]
}
pred.mat <- list(bma.pred[ ,1],rowMeans(ss.pred), gpriorUnit.pred$fit,gpriorBIC.pred$fit,
AIC.pred$fit, EBlocal.pred$fit, EBglobal.pred$fit, gsqrtn.pred$fit,
g1.pred$fit, hypergprior.pred$fit, nlp.pred[ ,1], HS.pred[ ,1],
sslasso.pred, emvs.pred[ ,1], scad.pred, mcp.pred,lasso.pred.min,
lasso.pred.1se,elastic.pred ,JZS.pred$fit, ZSnull.pred$fit, full.mod.pred[ ,1])
names(pred.mat) <- methods_Point
for (i in 1:length(methods_Point)){
mse_mat[b,i] <- MSE(y.true.test, pred.mat[[i]])
rmse_mat[b,i] <- rmse(y.true.test, pred.mat[[i]])
mae_mat[b,i] <- MAE(y.true.test, pred.mat[[i]])
r2test.mat[b,i] <- r2test(y.true.test,pred.mat[[i]])
}
phat.mat[b, ] <- cbind(bma.phat, ss.phat, gpriorUnit.phat,gpriorBIC.phat, AIC.phat,
EBlocal.phat,EBglobal.phat,gsqrtn.phat, g1.phat, hyperg.phat,
nlp.phat,HS.phat,sslasso.phat, EMVS.phat, scad.phat, mcp.phat,
lasso.min.phat,lasso.1se.phat, elastic.phat, JZS.phat, ZSnull.phat,
full.phat)
conf.mat <- list(bma.pred[ ,3:4], ss.conf, gpriorUnit.conf[ ,1:2], gpriorbic.conf[ ,1:2],
AIC.conf[ ,1:2],EBlocal.conf[ ,1:2],EBglobal.conf[ ,1:2], gsqrtn.conf[ ,1:2],
g1.conf, hypergprior.conf[ ,1:2],nlp.pred[,2:3], HS.pred[ ,2:3],
JZS.conf[ ,1:2],ZSnull.conf[ ,1:2],fullmod.conf)
for(j in 1:length(methods_Interval)){
conf.method <- conf.mat[[j]]
width_mat[b,j] <- mean(conf.method[ ,2]-conf.method[ ,1])
coverage_mat[b,j] <- sum(((y.true.test>conf.method[ ,1])&(y.true.test<conf.method[ ,2])))/ length(y.true.test)
IntervalScore_mat[b,j] <- meanintscore(conf.method[ ,2],conf.method[ ,1], y.true.test, a)
}
methods.pred.mat <- list(bma.pred.mat ,ss.pred, gpriorBIC.pred.mat, gpriorBIC.pred.mat,
AIC.pred.mat,EBlocal.pred.mat,EBglobal.pred.mat,gsqrtn.pred.mat,
g1.pred.mat,hypergprior.pred.mat,nlp.pred.mat,HS.pred.mat,
JZS.pred.mat,ZSnull.pred.mat)
for(j in 1:(length(methods_Interval)-1)){
CRPS_mat[b,j] <- CRPS_prediction(100, methods.pred.mat[[j]]  ,y.true.test)
}
}
#### Summary plots and tables #### ####----
# par(mfrow=c(2,4))
#
# for (w in 1:ncol(width_mat)){
#   hist(width_mat[ ,w], main = paste("PI-",colnames(width_mat)[w]), xlab = "Avg Width")
# }
sum_mat=cbind(colMeans(mse_mat), colMeans(mae_mat), colMeans(rmse_mat),
colMeans(r2test.mat),colMeans(phat.mat))
sum_mat2=cbind(colMeans(coverage_mat), colMeans(width_mat), colMeans(IntervalScore_mat),
colMeans(CRPS_mat))
colnames(sum_mat)=c("AMSE","AMAE","ARMSE","Average R^2 test", "average model size")
colnames(sum_mat2)=c("Mean coverage","Mean Width","Mean Interval score","CRPS")
results <- list("mse_mat"=mse_mat,"mae_mat"=mae_mat,"rmse_mat"=rmse_mat, "r2test_mat" = r2test.mat,
"phat.mat"=phat.mat,"coverage_mat"=coverage_mat, "width_mat"=width_mat, "CRPS_mat"=CRPS_mat,
"IntervalScore"=IntervalScore_mat, "point.pred.metric"=sum_mat,
"uncertainty.pred.metric"=sum_mat2)
return (results)
}
res2 <- prediction_study(Xmat = Xmat,Y=Y,bootn = 10,split = 0.75)
res1$point.pred.metric
res2$point.pred.metric
res1$uncertainty.pred.metric
res2$uncertainty.pred.metric
dconc.dens <- function(k,t){
t*(k*(1-k))^{t-1}/(k^t+(1-k)^t)^2
}
par(mfrow=c(1,1),cex.lab=1.3,cex.axis=1.5)
curve(dconc.dens(x,t=0.1), from = 0,to=1, n=8001, xlab = "kappa", lwd=2, col="green",
ylab = "Density up to constants",ylim=c(0,30),add=TRUE)#,main="Horseshoe")
curve(dconc.dens(x,t=0.1), from = 0,to=1, n=8001, xlab = "kappa", lwd=2, col="green",
ylab = "Density up to constants",ylim=c(0,30))#,main="Horseshoe")
curve(dconc.dens(x,t=0.01), from = 0,to=1, n=8001, xlab = "kappa", lwd=2, col="blue",
ylab = "Density up to constants",ylim=c(0,30),add=TRUE)#,main="Horseshoe")
curve(dconc.dens(x,t=0.5), from = 0,to=1, n=8001, xlab = "kappa", lwd=2, col="red",
ylab = "Density up to constants",ylim=c(0,30),add=TRUE)#,main="Horseshoe")
curve(dconc.dens(x,t=1), from = 0,to=1, n=8001, xlab = "kappa", lwd=2, col="black",
ylab = "Density up to constants",ylim=c(0,30),add=TRUE)#,main="Horseshoe")
curve(dconc.dens(x,t=2), from = 0,to=1, n=8001, xlab = "kappa", lwd=2, col="pink",
ylab = "Density up to constants",ylim=c(0,30),add=TRUE)#,main="Horseshoe")
curve(dconc.dens(x,t=0.1), from = 0,to=1, n=8001, xlab = "kappa", lwd=2, col="green",
ylab = "Density up to constants",ylim=c(0,30),add=TRUE)#,main="Horseshoe")
#### Libraries #### ----
library(mlbench)
library(reshape2)
library(ggplot2)
library(MASS)
library(BMA)
library(glmnet)
library(BAS)
library(EMVS)
library(SSLASSO)
library(horseshoe)
library(mombf)
library(networkBMA)
library(ncvreg)
library(BoomSpikeSlab)
library(ModelMetrics)
library(robustHD)
library(xtable)
library(ISLR)
library(parallel)
library(doParallel)
library(plyr)
library(xlsx)
library(XLConnect)
library(openxlsx)
library(SIS)
library(gss)
library(spikeslab)
registerDoParallel(cores=2)
#################### EDIT THIS PART ONLY ######################
#setwd("C:/Users/Anupreet Porwal/Dropbox/Research/BMA LASSO/code/BMA code")
source("src/prediction_study_function_011321.R")
source("src/est_varselection_function_SIS_011321.R")
source("src/est_varselection_function_011321.R")
source("src/est_varselection_function_011321.R")
library(caret)      # install.packages('caret', dependencies = c("Depends", "Suggests"))
library(mlbench)
library(MASS)
library(plyr)
library(PRROC)
library(glmnet)
library(BAS)
library(plyr)
library(testit)
setwd("C:/Users/Anupreet Porwal/Dropbox/Research/PEP-GLM/code")
load("data/simulation1_logistic_data.rda")
source("LaplacePEP_MCMC_ModelPrior_deltaPrior_010421.R")
#
set.seed(8)
args = commandArgs(TRUE)
samp <- 100
pep.predict.model <- function(gamsamp,estimator="HPM"){
if(estimator=="HPM"){
mod.sum <- count(as.data.frame(gamsamp), vars = colnames(gamsamp))
map.mod <- mod.sum[which.max(mod.sum$freq),-ncol(mod.sum)]
}
return(map.mod)
}
# ## Covariance matrix for correlated X
# Sigma = matrix(NA, nr = p, nc = p);
# for(k in 1:p){
#   for(l in 1:p){
#     Sigma[k,l] = 0.75^(abs(k-l));
#   }
# }
map.count <- matrix(0, nrow=samp,ncol = 11)
colnames(map.count) <- c("LPEP-BB-G1","LPEP-U-G1","LPEP-BB-G4","LPEP-U-G4","LPEP-BB-hyperg",
"LPEP-U-hyperg","LASSO","UIP", "hyper-g","hyper-g/n a=3",
"hyper-g/n a=4")#,"CR PEP","CR PEP hyper-g","CR PEP hyper-g/n a=4",
#"DR PEP", "DR PEP hyper-g","DR PEP hyper-g/n a=4")
i=j=1
library(caret)      # install.packages('caret', dependencies = c("Depends", "Suggests"))
library(mlbench)
library(MASS)
library(plyr)
library(PRROC)
library(glmnet)
library(BAS)
library(plyr)
library(testit)
#setwd("C:/Users/Anupreet Porwal/Dropbox/Research/PEP-GLM/code")
load("data/simulation1_logistic_data.rda")
source("LaplacePEP_MCMC_ModelPrior_deltaPrior_010421.R")
#source("PEPs/crpep_function_AP.R")
#source("PEPs/drpep_function_AP.R")
set.seed(8)
args = commandArgs(TRUE)
samp <- 100
pep.predict.model <- function(gamsamp,estimator="HPM"){
if(estimator=="HPM"){
mod.sum <- count(as.data.frame(gamsamp), vars = colnames(gamsamp))
map.mod <- mod.sum[which.max(mod.sum$freq),-ncol(mod.sum)]
}
return(map.mod)
}
# ## Covariance matrix for correlated X
# Sigma = matrix(NA, nr = p, nc = p);
# for(k in 1:p){
#   for(l in 1:p){
#     Sigma[k,l] = 0.75^(abs(k-l));
#   }
# }
map.count <- matrix(0, nrow=samp,ncol = 11)
colnames(map.count) <- c("LPEP-BB-G1","LPEP-U-G1","LPEP-BB-G4","LPEP-U-G4","LPEP-BB-hyperg",
"LPEP-U-hyperg","LASSO","UIP", "hyper-g","hyper-g/n a=3",
"hyper-g/n a=4")#,"CR PEP","CR PEP hyper-g","CR PEP hyper-g/n a=4",
#"DR PEP", "DR PEP hyper-g","DR PEP hyper-g/n a=4")
source("main/LaplacePEP_MCMC_ModelPrior_deltaPrior_010421.R")
source("main/LaplacePEP_MCMC_ModelPrior_deltaPrior_010421.R")
set.seed(8)
args = commandArgs(TRUE)
samp <- 100
pep.predict.model <- function(gamsamp,estimator="HPM"){
if(estimator=="HPM"){
mod.sum <- count(as.data.frame(gamsamp), vars = colnames(gamsamp))
map.mod <- mod.sum[which.max(mod.sum$freq),-ncol(mod.sum)]
}
return(map.mod)
}
# ## Covariance matrix for correlated X
# Sigma = matrix(NA, nr = p, nc = p);
# for(k in 1:p){
#   for(l in 1:p){
#     Sigma[k,l] = 0.75^(abs(k-l));
#   }
# }
map.count <- matrix(0, nrow=samp,ncol = 11)
colnames(map.count) <- c("LPEP-BB-G1","LPEP-U-G1","LPEP-BB-G4","LPEP-U-G4","LPEP-BB-hyperg",
"LPEP-U-hyperg","LASSO","UIP", "hyper-g","hyper-g/n a=3",
"hyper-g/n a=4")#,"CR PEP","CR PEP hyper-g","CR PEP hyper-g/n a=4",
i=j=1
r=1
library(caret)      # install.packages('caret', dependencies = c("Depends", "Suggests"))
library(mlbench)
library(MASS)
library(plyr)
library(PRROC)
library(glmnet)
library(BAS)
library(plyr)
library(testit)
#setwd("C:/Users/Anupreet Porwal/Dropbox/Research/PEP-GLM/code")
load("data/simulation1_logistic_data.rda")
source("main/LaplacePEP_MCMC_ModelPrior_deltaPrior_010421.R")
#source("PEPs/crpep_function_AP.R")
#source("PEPs/drpep_function_AP.R")
set.seed(8)
args = commandArgs(TRUE)
samp <- 100
pep.predict.model <- function(gamsamp,estimator="HPM"){
if(estimator=="HPM"){
mod.sum <- count(as.data.frame(gamsamp), vars = colnames(gamsamp))
map.mod <- mod.sum[which.max(mod.sum$freq),-ncol(mod.sum)]
}
return(map.mod)
}
# ## Covariance matrix for correlated X
# Sigma = matrix(NA, nr = p, nc = p);
# for(k in 1:p){
#   for(l in 1:p){
#     Sigma[k,l] = 0.75^(abs(k-l));
#   }
# }
map.count <- matrix(0, nrow=samp,ncol = 11)
colnames(map.count) <- c("LPEP-BB-G1","LPEP-U-G1","LPEP-BB-G4","LPEP-U-G4","LPEP-BB-hyperg",
"LPEP-U-hyperg","LASSO","UIP", "hyper-g","hyper-g/n a=3",
"hyper-g/n a=4")#,"CR PEP","CR PEP hyper-g","CR PEP hyper-g/n a=4",
i=j=1
r=1
print(paste0("Iteration no:",r))
ind = (2 * (i - 1) + j - 1) * 100 + r;
X = X.full[[ind]][, 1:p];
y = y.full[[ind]];
sim.data <- as.data.frame(cbind(X,y))
true.gam <- (abs(Betatrue[i, -1])>0)
c <- 1
print("----------------mod1------------")
# Laplace PEP
mod1 <- Laplace.pep(X,y,nmc=5000,burn=2000, model.prior = "beta-binomial", hyper="TRUE", hyper.type="gamma",hyper.param=1)
# colnames(LapPEP.fit$GammaSamples)=paste("V",1:5,sep="")
# # Count the unique models and their counts
# mod.sum <- count(as.data.frame(LapPEP.fit$GammaSamples), vars = paste("V",1:5,sep=""))
#
# Count the unique models and their counts
map.1 <- pep.predict.model(mod1$GammaSamples,estimator = "HPM")
if(all(true.gam==map.1)){
map.count[r,c] <-1
}
c=c+1
print("----------------mod2------------")
mod2 <- Laplace.pep(X,y,nmc=5000,burn=2000, model.prior = "Uniform", hyper="TRUE", hyper.type="gamma",hyper.param=1)
map.2 <- pep.predict.model(mod2$GammaSamples,estimator = "HPM")
if(all(true.gam==map.2)){
map.count[r,c] <-1
}
c=c+1
print("----------------mod3------------")
mod3 <- Laplace.pep(X,y,nmc=5000,burn=2000, model.prior = "beta-binomial", hyper="TRUE", hyper.type="gamma",hyper.param=4)
map.3 <- pep.predict.model(mod3$GammaSamples,estimator = "HPM")
if(all(true.gam==map.3)){
map.count[r,c] <-1
}
c=c+1
print("----------------mod4------------")
mod4 <- Laplace.pep(X,y,nmc=5000,burn=2000, model.prior = "Uniform", hyper="TRUE", hyper.type="gamma",hyper.param=4)
map.4 <- pep.predict.model(mod4$GammaSamples,estimator = "HPM")
if(all(true.gam==map.4)){
map.count[r,c] <-1
}
c=c+1
print("----------------mod5------------")
mod5 <- Laplace.pep(X,y,nmc=5000,burn=2000, model.prior = "beta-binomial", hyper="TRUE", hyper.type="hyper-g/n",hyper.param=4)
map.5 <- pep.predict.model(mod5$GammaSamples,estimator = "HPM")
if(all(true.gam==map.5)){
map.count[r,c] <-1
}
c=c+1
print("----------------mod6------------")
mod6 <- Laplace.pep(X,y,nmc=5000,burn=2000, model.prior = "Uniform", hyper="TRUE", hyper.type="hyper-g/n",hyper.param=4)
map.6 <- pep.predict.model(mod6$GammaSamples,estimator = "HPM")
if(all(true.gam==map.6)){
map.count[r,c] <-1
}
c=c+1
# LASSO
lasso.fit <- cv.glmnet(X, y, family = "binomial")
lasso.mod <- (abs(coef(lasso.fit,s="lambda.min"))>0)[-1]
if(all(true.gam==lasso.mod)){
map.count[r,c] <-1
}
c=c+1
# UIP
UIP.fit <- bas.glm( y~ ., data=sim.data,method="BAS", family=binomial(link = "logit")
,betaprior = g.prior(n))
UIP.hpm <- predict(UIP.fit, estimator = "HPM")
UIP.hpm.mod <- colnames(X) %in%  variable.names(UIP.hpm)
if(all(true.gam==UIP.hpm.mod)){
map.count[r,c] <-1
}
c=c+1
# Hyper g
hyperg.fit <- bas.glm( y~ ., data=sim.data,method="BAS", family=binomial(link = "logit")
,betaprior = hyper.g(alpha=3))
hyperg.hpm <- predict(hyperg.fit, estimator = "HPM")
hyperg.hpm.mod <- colnames(X) %in%  variable.names(hyperg.hpm)
if(all(true.gam==hyperg.hpm.mod)){
map.count[r,c] <-1
}
c=c+1
# Hyper g/n alpha =3
hypergna3.fit <- bas.glm( y~ ., data=sim.data,method="BAS", family=binomial(link = "logit")
,betaprior = hyper.g.n(alpha=3,nrow(sim.data)))
hypergna3.hpm <- predict(hypergna3.fit, estimator = "HPM")
hypergna3.hpm.mod <- colnames(X) %in%  variable.names(hypergna3.hpm)
if(all(true.gam==hypergna3.hpm.mod)){
map.count[r,c] <-1
}
c=c+1
# Hyper g/n alpha =4 ; median is n
hypergn.fit <- bas.glm( y~ ., data=sim.data,method="BAS", family=binomial(link = "logit")
,betaprior = hyper.g.n(alpha=4,nrow(sim.data)))
hypergn.hpm <- predict(hypergn.fit, estimator = "HPM")
hypergn.hpm.mod <- colnames(X) %in%  variable.names(hypergn.hpm)
if(all(true.gam==hypergn.hpm.mod)){
map.count[r,c] <-1
}
c=c+1
# # CRPEP
# PEP.y.input <- cbind(rep(1,length(y)),y)
# crpep.fit <- gvs.crpep(PEP.y.input, X,iter=6000, discard = 1000, family = "binomial",
#                        n.star = length(y),hyper = FALSE)
# map.crpep <- pep.predict.model(crpep.fit$gammas,estimator = "HPM")
# if(all(true.gam==map.crpep)){
#   map.count[r,c] <-1
# }
# c=c+1
#
# #CRPEP - hyper g - GIVES ERROR RIGHT NOW
# crpep.hyperg.fit <- gvs.crpep(PEP.y.input, X,iter=6000, discard = 1000, family = "binomial",
#                               n.star = length(y),hyper = TRUE, hyper.type = "hyper-g")
# map.crpep.hyperg <- pep.predict.model(crpep.hyperg.fit$gammas,estimator = "HPM")
# if(all(true.gam==map.crpep.hyperg)){
#   map.count[r,c] <-1
# }
# c=c+1
#
#
# # CRPEP - hyper g/n
# crpep.hypergn.fit <- gvs.crpep(PEP.y.input, X,iter=6000, discard = 1000, family = "binomial",
#                                n.star = length(y),hyper = TRUE, hyper.type = "hyper-g/n")
# map.crpep.hypergn <- pep.predict.model(crpep.hypergn.fit$gammas,estimator = "HPM")
# if(all(true.gam==map.crpep.hypergn)){
#   map.count[r,c] <-1
# }
# c=c+1
#
#
#
# # DR PEP
# drpep.fit <- gvs.drpep(PEP.y.input, X,iter=6000, discard = 1000, family = "binomial",
#                        n.star = length(y),hyper = FALSE)
# map.drpep <- pep.predict.model(drpep.fit$gammas,estimator = "HPM")
# if(all(true.gam==map.drpep)){
#   map.count[r,c] <-1
# }
# c=c+1
#
# # DR PEP - hyper g
# drpep.hyperg.fit <- gvs.drpep(PEP.y.input, X,iter=6000, discard = 1000, family = "binomial",
#                               n.star = length(y),hyper = TRUE, hyper.type = "hyper-g")
# map.drpep.hyperg <- pep.predict.model(drpep.hyperg.fit$gammas,estimator = "HPM")
# if(all(true.gam==map.drpep.hyperg)){
#   map.count[r,c] <-1
# }
# c=c+1
#
#
#
# # DR PEP - hyper g/n
# drpep.hypergn.fit <- gvs.drpep(PEP.y.input, X,iter=6000, discard = 1000, family = "binomial",
#                                n.star = length(y),hyper = TRUE, hyper.type = "hyper-g/n")
# map.drpep.hypergn <- pep.predict.model(drpep.hypergn.fit$gammas,estimator = "HPM")
# if(all(true.gam==map.drpep.hypergn)){
#   map.count[r,c] <-1
# }
# c=c+1
print(colSums(map.count))
